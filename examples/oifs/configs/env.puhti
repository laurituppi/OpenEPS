#!/bin/bash
#
# ENVIRONMENT SPECIFIC SETTINGS
#

#-----------------------------------------------
# SYSTEM - TAITO - SUPERCOMPUTER
#-----------------------------------------------
# Number of cores per node
SYS_CPUSPERNODE=40

# Taito nodes are shared for jobs, better for job scheduling to reserve cpus instead of nodes
if [ -z $CPUSTOT ]; then
    CPUSTOT=$(echo "$NNODES * $SYS_CPUSPERNODE" | bc)
fi
export CPUSTOT


# Path structure
WORK=/scratch/project_2001011/Lauri/openEPS/$EXPL
SCRI=$WORK/scripts
DATA=$WORK/data
SRC=$WORK/configs
export WORK SCRI DATA SRC

# Estimate bulk job time if TIMEFORMODEL given instead of EXPTIME
if [ -z $EXPTIME ]; then
    mandtg=$WORK/mandtg

    totperday=$(echo "$TIMEFORMODEL * $ENS" | bc)
    totdays=$($mandtg $EDATE - $SDATE)
    totdays=$(echo "$totdays / $DSTEP + 1" | bc)
    totmins=$(echo "$totperday * $totdays" | bc)
    parallels=$(echo "$CPUSTOT / $CPUSPERMODEL" | bc)
    tottime=$(echo "$totmins / $parallels" | bc)

    modul=$(printf '%02d' $(($tottime % 60)))
    EXPTIME=$(echo "$tottime / 60" | bc)":$modul:00"
fi
export EXPTIME

# Match batchjob queue with requested resources
if [ -z $BATCHQUEUE ]; then
    if [ $CPUSTOT -le 80 ]; then
	BATCHQUEUE=test
    else
	BATCHQUEUE=small
    fi
fi

# Batch job specification
# If unspecified or false, run on local resources
SEND_AS_SINGLEJOB="true" # send whole main.bash to queue
SEND_AS_MULTIJOB="false"   # only send run.bash to queue
line1="#SBATCH --account=project_2001011"
line2="#SBATCH --partition=$BATCHQUEUE"       # batchjob queue
line3="#SBATCH --job-name=$EXPS"             # name
line4="#SBATCH --time=$EXPTIME"          # time reservation
line5="#SBATCH --ntasks=$CPUSTOT"          # cores tot
#line4="#SBATCH -N $NNODES"  # hmm, taitaa olla hidas
line6='#SBATCH --mem-per-cpu=2G'   # memory per core in MB
line7='#SBATCH --output=out.txt'               # where to write output 
line8='#SBATCH --error=err.txt'               # where to write error

# Load modules
#module load openifs
module purge
module load intel/19.0.4 hpcx-mpi/2.4.0 intel-mkl/2019.0.4
module load eccodes perl fftw/3.3.8-mpi netcdf/4.7.0 netcdf-fortran/4.4.4
#module load eccodes #grib-api
export ECCODES_SAMPLES_PATH=${ECCODES_INSTALL_ROOT}/share/eccodes/ifs_samples/grib1_mlgrib2
module load cdo

#-----------------------------------------------
# MODEL SPECIFIC DIRS AND SETTINGS
#-----------------------------------------------
# Default model path
if [ -z $MODEL_EXE ]; then
    MODEL_EXE=/projappl/project_2001011/OpenIFS/intel_19.0.4/cy40r1v2/master.exe
fi

# Initial states
INIBASEDIR=/scratch/project_2001011/OIFS_INI

# Paths to initial states
IFSDATA=/projappl/project_2001011/OpenIFS/40r1v2_climatology

export MODEL_EXE
export INIBASEDIR IFSDATA IFSDATA2 GRIB_SAMPLES_PATH
export LD_LIBRARY_PATH

# Increase stack memory (model may crash with SEGV otherwise)
ulimit -s unlimited

# Grib-tools needed
#export GRIBTOOLS=/homeappl/home/ollinaho/grib-api/bin
export GRIBTOOLS=/appl/spack/install-tree/gcc-4.8.5/eccodes-2.5.0-f6buba/bin


# --------------------------------------------------------------
# TESTING
# --------------------------------------------------------------
# Vital paths that must exist
REQUIRE_PATHS="$REQUIRE_PATHS INIBASEDIR IFSDATA GRIB_SAMPLES_PATH"

# Vital variables that must exist	
REQUIRE_VARS="$REQUIRE_VARS WORK SCRI DATA SRC OMP_NUM_THREADS DR_HOOK"
